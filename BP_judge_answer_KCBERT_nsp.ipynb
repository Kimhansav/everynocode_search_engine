{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMDgLF93fovS/0GzfR1TW2L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kimhansav/everynocode_search_engine/blob/main/BP_judge_answer_KCBERT_nsp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wabey716zPNq"
      },
      "outputs": [],
      "source": [
        "#한국 버블 커뮤니티 오픈톡방 대화의 질문에 대한 답변을 선별하는 코드(BERT Next Sentence Prediction)(로컬)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6eFub4T38V1"
      },
      "outputs": [],
      "source": [
        "!pip install soynlp\n",
        "!pip install datasets\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import os\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "import urllib.request\n",
        "from soynlp.word import WordExtractor\n",
        "from tqdm import tqdm\n",
        "from kobert_transformers import get_kobert_model, get_tokenizer\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from transformers import AutoTokenizer, shape_list, TFBertModel, RobertaTokenizerFast, RobertaForSequenceClassification, TextClassificationPipeline, pipeline, BertTokenizer, BertForNextSentencePrediction,  TrainingArguments\n",
        "from datasets import Dataset, load_dataset\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHdWohm7tup8"
      },
      "outputs": [],
      "source": [
        "#모델 불러오기\n",
        "HUGGINGFACE_MODEL_PATH = 'beomi/kcbert-base'\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(HUGGINGFACE_MODEL_PATH)\n",
        "model = BertForNextSentencePrediction.from_pretrained(HUGGINGFACE_MODEL_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWN3N25M0FdD"
      },
      "outputs": [],
      "source": [
        "# #훈련 데이터 불러오기\n",
        "# pretrain_dataset_path = '/content/drive/My Drive/KcBERT_pretrain_dataset.xlsx'\n",
        "# finetune_dataset_path = '/content/drive/My Drive/KcBERT_finetune_dataset.xlsx'\n",
        "\n",
        "# df_pretrain = df.read_excel(pretrain_dataset_path)\n",
        "# df_finetune = df.read_excel(finetune_dataset_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pretrain_dataset_path = '/content/drive/My Drive/KcBERT_pretrain_dataset.xlsx'\n",
        "df_pretrain = df.read_excel(pretrain_dataset_path)"
      ],
      "metadata": {
        "id": "Yw42MGfKe5A2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#soynlp tokenizer를 Pretrain 데이터로 학습\n",
        "pretrain_list = df_pretrain['text'].to_list()\n",
        "\n",
        "word_extractor = WordExtractor()\n",
        "word_extractor.train(pretrain_list)\n",
        "word_score_table = word_extractor.extract()"
      ],
      "metadata": {
        "id": "Qs1LsIZcp-hj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_score_table)"
      ],
      "metadata": {
        "id": "LnnplUtjbjk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 예제로 몇 가지 단어 점수 확인\n",
        "for word, score in word_scores.items():\n",
        "    print(f\"{word}: {score.cohesion_forward:.2f}\")"
      ],
      "metadata": {
        "id": "YgSr7iXqePiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 높은 cohesion 점수를 가진 단어들을 선택하여 단어사전 구성\n",
        "threshold = 0.1  # 점수 기준 설정\n",
        "new_vocab = [word for word, score in word_scores.items() if score.cohesion_forward > threshold]\n",
        "\n",
        "# 선택된 단어 출력\n",
        "print(new_vocab)"
      ],
      "metadata": {
        "id": "pzm-dfEzeUJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# KcBERT 토크나이저 로드\n",
        "tokenizer = BertTokenizer.from_pretrained('beomi/kcbert-base')\n",
        "model = BertModel.from_pretrained('beomi/kcbert-base')\n",
        "\n",
        "# 새로운 단어 토크나이저에 추가\n",
        "num_added_toks = tokenizer.add_tokens(new_vocab)\n",
        "print(f\"Added {num_added_toks} tokens\")\n",
        "\n",
        "# 모델의 임베딩 크기 조정\n",
        "model.resize_token_embeddings(len(tokenizer))"
      ],
      "metadata": {
        "id": "0nQBWVrDeVoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcQirWwI0K1l"
      },
      "outputs": [],
      "source": [
        "#카카오톡 데이터 불러오기\n",
        "file_path = '/content/drive/My Drive/judge_question_result.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03vWAudThdM2"
      },
      "outputs": [],
      "source": [
        "#카카오톡 대화내용을 데이터프레임으로 받기\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "#질문 딕셔너리, 답변 목록 리스트(이중 리스트) 생성\n",
        "questions, answer_lists = {}, []\n",
        "\n",
        "#질문으로 판별된 텍스트를 새 데이터프레임으로 생성\n",
        "df_question = df[df['label'] == 'question']\n",
        "\n",
        "print(df_question)\n",
        "#새 데이터프레임의 index, text를 question 딕셔너리에 저장\n",
        "questions = {text : index for (index, text) in zip(df_question.index, df_question['text'])}\n",
        "print(questions)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure the classifier is using GPU\n",
        "device = 0 if torch.cuda.is_available() else -1  # Use GPU if available, otherwise CPU\n",
        "print(device)\n",
        "classifier = pipeline('zero-shot-classification', model=HUGGINGFACE_MODEL_PATH, device=device, batch_size = 64)"
      ],
      "metadata": {
        "id": "yyaMglos92s_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 문장 정의\n",
        "sentence_a = \"안녕하세요. 저는 학생입니다.\"\n",
        "sentence_b = \"공부를 많이 하고 있어요.\"\n",
        "\n",
        "# 인코딩 및 NSP 태스크 준비\n",
        "encoded = tokenizer.encode_plus(sentence_a, sentence_b, return_tensors='pt')\n",
        "with torch.no_grad():\n",
        "    outputs = model(**encoded, next_sentence_label=torch.LongTensor([1]))\n",
        "    logits = outputs.logits\n",
        "\n",
        "# 결과 해석\n",
        "predicted_label = torch.argmax(logits).item()\n",
        "\n",
        "if predicted_label == 1:\n",
        "    print(\"문장 B는 문장 A의 뒤에 올 수 있습니다.\")\n",
        "else:\n",
        "    print(\"문장 B는 문장 A의 뒤에 올 수 없습니다.\")\n"
      ],
      "metadata": {
        "id": "kn4ZKaydg2iV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfFU5ST9Nyau"
      },
      "outputs": [],
      "source": [
        "#중복 질문 제거를 동시에 수행하기 위한 새로운 알고리즘\n",
        "\n",
        "#실험을 위한 하이퍼파라미터 설정\n",
        "#후보군으로 삼을 텍스트 개수 범위\n",
        "text_range = 20\n",
        "#답변 목록에 추가할지 기준이 되는 레이블값\n",
        "#질문-질문 비교기준\n",
        "qstandard = 0.6\n",
        "#질문-답변 비교기준\n",
        "astandard = 0.6\n",
        "\n",
        "#질문-답변 쌍 딕셔너리 생성\n",
        "qa_pair_dictionary = {index : {'질문' : question, '답변' : []} for index, question in zip(df_question.index, df_question['text'])}\n",
        "\n",
        "#질문 속 질문인지 판별할 때 사용할 불리언\n",
        "in_question_texts = False\n",
        "\n",
        "all_texts = {index : item for index, item in zip(df.index, df['text'])}\n",
        "\n",
        "for index, item in tqdm(all_texts.items(), desc = 'Processing Answer to Question'):\n",
        "\n",
        "  candidate_qa_list = [] #현재 텍스트의 소속을 판정할 (질문-답변 딕셔너리) 리스트\n",
        "  candidate_qa_index_list = []\n",
        "  in_question_texts = True if df.iloc[index]['label'] == 'question' else False #판별할 텍스트가 질문인지 검사\n",
        "\n",
        "  start = 0 if index < 20 else index - text_range - 1 #인덱스가 20 미만일 경우 검사 범위 조정\n",
        "  for i in range(start, index): #현재 텍스트가 소속될 질문의 범위\n",
        "    candidate = qa_pair_dictionary.get(i, None) #qa_pair_dictionary에서 i 인덱스에 해당하는 질답 딕셔너리 가져오기\n",
        "    if candidate != None:\n",
        "      candidate_qa_list.append(candidate) #결과 리스트에서 최대 확률인 질문을 인덱싱하기 위해 인덱스를 포함한 딕셔너리를 append\n",
        "      candidate_qa_index_list.append(i)\n",
        "\n",
        "  if len(candidate_qa_list) == 0:\n",
        "    continue\n",
        "\n",
        "  #데이터 배치처리\n",
        "  sequence_to_classify = [qa_dict['질문'] + ' '.join(qa_dict['답변']) + '[END]' + item for qa_dict in candidate_qa_list] #[qa_dict['질문'] + '[END]' + item for qa_dict in candidate_qa_list] if in_question_texts == True else [qa_dict['질문'] + ' '.join(qa_dict['답변']) + '[END]' + item for qa_dict in candidate_qa_list]\n",
        "\n",
        "  #동적 레이블\n",
        "  candidate_labels = [\"뒤의 질문은 앞의 글과 거의 같은 주제이다\", \"뒤의 질문은 앞의 글과 거의 같은 주제가 아니다\"] if in_question_texts == True else [\"질문-답변 쌍이다\", \"질문-답변 쌍이 아니다\"] #\"거의 같은 주제의 질문이다\", \"거의 같은 주제의 질문이 아니다\"\n",
        "\n",
        "  output = classifier(sequence_to_classify, candidate_labels, hypothesis_template = '[END]를 기준으로 두 질문을 구분했을 때 {}.' if in_question_texts == True else '[END]를 기준으로 두 글을 구분했을 때 {}.', multi_label=False)\n",
        "  expected_label = \"질문-답변 쌍이다\" if in_question_texts == False else \"뒤의 질문은 앞의 글과 거의 같은 주제이다\"\n",
        "\n",
        "  #output 딕셔너리에 질문 인덱스를 추가\n",
        "  for i in range(len(output)):\n",
        "    output[i]['index'] = candidate_qa_index_list[i]\n",
        "\n",
        "  # 'scores'의 첫 번째 값(expected label일 확률)에 따라 내림차순으로 정렬\n",
        "  sorted_output = sorted(output, key = lambda x : x['scores'][0], reverse=True)\n",
        "\n",
        "  output = sorted_output[0] #텍스트가 소속될 질문\n",
        "\n",
        "  #경우에 따른 기준값 변화 적용\n",
        "  if (in_question_texts == True and output['labels'][0] == expected_label and output['scores'][0] > qstandard) or (in_question_texts == False and output['labels'][0] == expected_label and output['scores'][0] > astandard):\n",
        "    #모순이 발생하지 않기 위해서 질문 속 질문으로 판별된 경우 즉시 qa_pair_dictionary에서 해당 질문을 삭제해야 함.\n",
        "    if in_question_texts == True:\n",
        "        del qa_pair_dictionary[index]\n",
        "\n",
        "    qa_pair_dictionary[output['index']]['답변'].append(item)\n",
        "\n",
        "\n",
        "  # print('\\n',qa_pair_dictionary)\n",
        "  # print('\\n',used_question_index)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XinB54vVC31p"
      },
      "outputs": [],
      "source": [
        "print(answer_lists, end = '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpfHnw9R61mZ"
      },
      "outputs": [],
      "source": [
        "# #데이터프레임 가공\n",
        "# df_question.rename(columns = {'text' : 'question'})\n",
        "# df_question['answer'] = answer_lists\n",
        "\n",
        "data = {question : answer for question, answer in zip(questions.keys(), answer_lists)}\n",
        "print(data)\n",
        "data_result= [{'question' : key, 'answer' : value} for key, value in data.items()]\n",
        "df_result = pd.DataFrame(data = data_result, columns = ['question', 'answer'])\n",
        "print(df_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXT7YkGs1Ede"
      },
      "outputs": [],
      "source": [
        "#.csv 파일로 google drive에 저장\n",
        "save_path = '/content/drive/My Drive/judge_answer_result.csv'\n",
        "\n",
        "df_result.to_csv(save_path)"
      ]
    }
  ]
}