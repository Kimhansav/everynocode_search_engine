{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNDWcC+TO5JpMAOdpTfruLg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kimhansav/everynocode_search_engine/blob/main/BP_sentence_embed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LztO7YqFzWXC"
      },
      "outputs": [],
      "source": [
        "#질답세션의 임베딩 벡터를 추가한 뒤 .csv로 저장하는 코드(로컬)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu #서버 업로드 시 삭제\n",
        "!pip install -U sentence-transformers #서버 업로드 시 삭제\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import urllib.request\n",
        "import faiss\n",
        "import time\n",
        "import torch\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from google.colab import drive\n",
        "from transformers import RobertaTokenizerFast, RobertaForSequenceClassification, TextClassificationPipeline, pipeline\n",
        "import torch.nn as nn\n",
        "!pip install datasets"
      ],
      "metadata": {
        "id": "2DwgUHmX36wG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaTokenizerFast, RobertaForSequenceClassification, Trainer, TrainingArguments\n",
        "from datasets import Dataset, load_dataset\n",
        "import torch\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split"
      ],
      "metadata": {
        "id": "0r4dqIYlJfpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#구글 드라이브 마운트\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgtCXPibJK3F",
        "outputId": "f54a52ce-4d94-4268-96e7-112d12787120"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#.csv파일 불러오기\n",
        "file_path = '/content/drive/My Drive/summary_result.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "#데이터프레임의 question 열을 리스트로 변형\n",
        "data = df.question.to_list()"
      ],
      "metadata": {
        "id": "oQf5evuuBLv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 로드\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "HUGGINGFACE_MODEL_PATH = 'BM-K/KoSimCSE-roberta-multitask'\n",
        "\n",
        "model = AutoModel.from_pretrained(HUGGINGFACE_MODEL_PATH)\n",
        "tokenizer = AutoTokenizer.from_pretrained(HUGGINGFACE_MODEL_PATH)\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "88NJoY1BN2S6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#수동 배치처리\n",
        "batch_size = 64\n",
        "\n",
        "result = []\n",
        "for i in tqdm(range(0, len(data), batch_size), desc = \"Embedding\"):\n",
        "    batch_texts = data[i : i + batch_size]\n",
        "    inputs = tokenizer(batch_texts, padding = True, truncation = True, return_tensors = 'pt')\n",
        "    inputs = {k : v.to(device) for k, v in inputs.items()}\n",
        "    #모델 실행\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    mean_pooling = torch.mean(outputs.last_hidden_state, dim = 1)\n",
        "    result.append(mean_pooling)\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "id": "CSdMKtRqI5Mr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(result))\n",
        "print(len(result[0]))\n",
        "print(len(result[0][0]))"
      ],
      "metadata": {
        "id": "gHNAsmdRWoNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터프레임에 새로운 열로 추가\n",
        "df['embedding'] = [sentence.cpu().numpy() for batches in result for sentence in batches]\n",
        "\n",
        "#csv파일로 저장할 때 쉼표가 사라지지 않게 해야 함, json.dumps 사용\n",
        "df['embedding'] = df['embedding'].apply(lambda x: json.dumps(x.tolist()))"
      ],
      "metadata": {
        "id": "N4P4gHCvoPWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df['embedding'][55]))\n",
        "print(df['embedding'])"
      ],
      "metadata": {
        "id": "Ov26jrvvfSg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#.csv 파일로 google drive에 저장 (나중에 google cloud storage에 저장해야 함)\n",
        "save_path = '/content/drive/My Drive/sentence_embed_result.csv'\n",
        "\n",
        "df.to_csv(save_path)"
      ],
      "metadata": {
        "id": "ei0zhSmmn0oO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "#로컬용 FAISS 코드\n",
        "#데이터 불러오기\n",
        "test_file_path = '/content/drive/My Drive/sentence_embed_result.csv'\n",
        "df = pd.read_csv(test_file_path)\n",
        "\n",
        "#csv파일로 저장할 때 쉼표를 살리기 위해 json.dumps로 저장했기 때문에 json.loads 사용\n",
        "df['embedding'] = df['embedding'].apply(json.loads)\n",
        "encoded_data = torch.tensor(df['embedding'].tolist())\n",
        "data = df.drop(['embedding'], axis = 1)\n",
        "\n",
        "#FAISS에 등록\n",
        "index = faiss.IndexIDMap(faiss.IndexFlatIP(768))\n",
        "print(encoded_data)\n",
        "index.add_with_ids(encoded_data, np.array(range(0, len(data))))\n",
        "faiss.write_index(index, 'question-answer')\n"
      ],
      "metadata": {
        "id": "mm6MyWLfsPRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#검색 함수에서 사용할 사용자 입력 인코딩 함수\n",
        "def encode(query):\n",
        "  inputs = tokenizer(query, padding = True, truncation = True, return_tensors = 'pt')\n",
        "\n",
        "  with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "  #배치 단위가 아니라 단일 문장이기 때문에 mean pooling을 할 때 dim = 0으로 설정\n",
        "  mean_pooling = torch.mean(outputs.last_hidden_state, dim = 0)\n",
        "  return mean_pooling"
      ],
      "metadata": {
        "id": "K-GiBAqUuUu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search(query):\n",
        "  t = time.time()\n",
        "  query_vector = encode(query)\n",
        "  k = 20\n",
        "  top_k = index.search(query_vector, k)\n",
        "  print('total time: {}'.format(time.time() - t))\n",
        "\n",
        "  return [{'question': data.iloc[_id]['question'], 'answer': data.iloc[_id]['answer'], 'question_summary': data.iloc[_id]['question_summary'], 'answer_summary': data.iloc[_id]['answer_summary']} for _id in top_k[1].tolist()[0]]"
      ],
      "metadata": {
        "id": "mXQAo813f1Ka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = str(input())\n",
        "results = search(query)\n",
        "print('results :')\n",
        "\n",
        "for result in results:\n",
        "  print('\\t Question summary :', result['question_summary'], '\\n')\n",
        "  print('\\t Answer summary :', result['answer_summary'], '\\n')\n",
        "  print('\\t Question :', result['question'], '\\n')\n",
        "  print('\\t Answer :', result['answer'], '\\n\\n\\n')"
      ],
      "metadata": {
        "id": "RimQrbGmf2Ua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TwXELwSot2wF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}