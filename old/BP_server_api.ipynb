{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOXM5MpXoKhDGasjjGe7GWk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kimhansav/everynocode_search_engine/blob/main/BP_server_api.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#질답세션 리턴 코드 import해서 서버에서 구동하는 코드(서버)"
      ],
      "metadata": {
        "id": "AkX_Rj9izvYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu #서버 업로드 시 삭제\n",
        "!pip install -U sentence-transformers #서버 업로드 시 삭제\n",
        "!pip install datasets\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import urllib.request\n",
        "import faiss\n",
        "import time\n",
        "import json\n",
        "import ast\n",
        "import torch\n",
        "from flask import Flask, request, jsonify\n",
        "from transformers import RobertaTokenizerFast, RobertaForSequenceClassification, AutoModel, AutoTokenizer\n",
        "from datasets import Dataset, load_dataset\n",
        "from sentence_transformers import SentenceTransformer"
      ],
      "metadata": {
        "id": "ggrU1wbl9c9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "#구글 드라이브 마운트\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "fYfJApNxScos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#캐싱 필요. 서버에 데이터 캐싱을 해야 함.\n",
        "#csv파일(혹은 데이터프레임 형태로 캐싱?), feature extraction 모델, FAISS 인덱싱 이 셋을 캐싱해둬야 함."
      ],
      "metadata": {
        "id": "pO9VztW9IFdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nh7sNvZsILWG"
      },
      "outputs": [],
      "source": [
        "app = Flask(__name__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 경로를 글로벌 변수로 지정\n",
        "global HUGGINGFACE_MODEL_PATH = 'BM-K/KoSimCSE-roberta-multitask'"
      ],
      "metadata": {
        "id": "p62s3q3pJXGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#검색 함수에서 사용할 사용자 입력 인코딩 함수\n",
        "def encode(query):\n",
        "  inputs = tokenizer(query, padding = True, truncation = True, return_tensors = 'pt')\n",
        "\n",
        "  with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "  #배치 단위가 아니라 단일 문장이기 때문에 mean pooling을 할 때 dim = 0으로 설정\n",
        "  mean_pooling = torch.mean(outputs.last_hidden_state, dim = 0)\n",
        "  return mean_pooling"
      ],
      "metadata": {
        "id": "h44YPWDSp1KA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#검색 함수\n",
        "def search(query):\n",
        "  t = time.time()\n",
        "  query_vector = encode(query)\n",
        "  k = 20\n",
        "  top_k = index.search(query_vector, k)\n",
        "  print('total time: {}'.format(time.time() - t))\n",
        "\n",
        "  return [{'question': data.iloc[_id]['question'], 'answer': data.iloc[_id]['answer'], 'question_summary': data.iloc[_id]['question_summary'], 'answer_summary': data.iloc[_id]['answer_summary']} for _id in top_k[1].tolist()[0]]"
      ],
      "metadata": {
        "id": "Z1JaFJKaK_8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#초기 호출 시 모델과 토크나이저를 전역 변수로 서버에 캐싱하는 함수\n",
        "def load_model_tokenizer():\n",
        "    model = AutoModel.from_pretrained(HUGGINGFACE_MODEL_PATH)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(HUGGINGFACE_MODEL_PATH)\n",
        "    return model, tokenizer"
      ],
      "metadata": {
        "id": "c1JVSzR8z6-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#초기 호출 시 csv 데이터를 데이터프레임으로 변형, 데이터프레임과 FAISS 인덱스를 전역 변수로 서버에 캐싱하는 함수\n",
        "def load_df_index():\n",
        "    #데이터 불러오기\n",
        "    test_file_path = '/content/drive/My Drive/sentence_embed_result.csv'\n",
        "    df = pd.read_csv(test_file_path)\n",
        "\n",
        "    #csv파일로 저장할 때 쉼표를 살리기 위해 json.dumps로 저장했기 때문에 json.loads 사용\n",
        "    df['embedding'] = df['embedding'].apply(json.loads)\n",
        "    encoded_data = torch.tensor(df['embedding'].tolist())\n",
        "\n",
        "    #속도를 위해 임베딩 열을 제외한 데이터프레임을 설정\n",
        "    #인덱싱 속도를 위해서 데이터프레임을 리스트로 변환\n",
        "    data = df.drop(['embedding'], axis = 1)\n",
        "\n",
        "    # FAISS 인덱스 구축\n",
        "    index = faiss.IndexIDMap(faiss.IndexFlatIP(768))\n",
        "    index.add_with_ids(encoded_data, np.array(range(0, len(data))))\n",
        "    faiss.write_index(index, 'question-answer')\n",
        "    return df, index"
      ],
      "metadata": {
        "id": "iZW4XbiKz7SS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#첫 실행에 호출되며 데이터를 캐싱하는 함수\n",
        "model = None\n",
        "tokenizer = None\n",
        "index = None\n",
        "df = None\n",
        "\n",
        "@app.before_first_request\n",
        "def load_resources():\n",
        "    global model, tokenizer, index, df\n",
        "    if model is None or tokenizer is None or index is None or df is None:\n",
        "        model, tokenizer = load_model_tokenizer() # 모델, 토크나이저 로딩 함수\n",
        "        df, index = load_df_index() #데이터프레임, 인덱스 로딩 함수"
      ],
      "metadata": {
        "id": "_xXcAJES39Zb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@app.route('/search', methods=['GET'])\n",
        "def find_similar():\n",
        "    user_input = request.args.get('q')\n",
        "    # 유사도 계산 및 가장 유사한 텍스트 찾기 (여기서는 로직 구현 필요)\n",
        "    results = search(user_input)\n",
        "    return jsonify(results)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)"
      ],
      "metadata": {
        "id": "GKxlXZQ4eEls"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
